{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 2016. 4. 26\n",
    "\n",
    "@author: dato\n",
    "@desc: cnlp hw8 (max entropy classifier)\n",
    "'''\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import io\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = './wsd_dataset.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of doc : 4937\n"
     ]
    }
   ],
   "source": [
    "f = io.open(data_file, 'r', encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "total_doc = len(lines)\n",
    "parsed_lines = [line.split('\\t') for line in lines]\n",
    "\n",
    "print 'total # of doc : ' + str(total_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apple = []\n",
    "pear = []\n",
    "potato = []\n",
    "\n",
    "for parsed_line in parsed_lines:\n",
    "    tmp = parsed_line[0].split('_')[0]\n",
    "    \n",
    "    if( tmp == unicode('사과'.decode('utf-8'))):\n",
    "        apple.append(parsed_line)\n",
    "    elif( tmp == unicode('배'.decode('utf-8'))):\n",
    "        pear.append(parsed_line)\n",
    "    else:\n",
    "        potato.append(parsed_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n",
      "3868\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "print len(apple)\n",
    "print len(pear)\n",
    "print len(potato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random sampling data from list\n",
    "\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "def random_sample(list_data, portion):\n",
    "    \n",
    "    list_train = []\n",
    "    list_test = []\n",
    "    a = random.sample(xrange(len(list_data)), int(len(list_data)*portion))\n",
    "\n",
    "    for x in range(len(list_data)):\n",
    "        if x not in a:\n",
    "            list_train.append(list_data[x])\n",
    "        else:\n",
    "            list_test.append(list_data[x])\n",
    "    \n",
    "    return list_train, list_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "def preprocess_train_data(list_data):\n",
    "    \n",
    "    fianl_list = []\n",
    "    \n",
    "    # 0: label     # 1: left_sentence     # 2 : label     # 3 : righ_sentence\n",
    "    for data in list_data:\n",
    "        feature = {}\n",
    "        tokens=kkma.morphs(data[1])\n",
    "        # prepare feature\n",
    "        for token in tokens:\n",
    "            if token in feature:\n",
    "                feature[token] += 1\n",
    "            else:\n",
    "                feature[token] =1\n",
    "                \n",
    "        tokens=kkma.morphs(data[3])\n",
    "        # prepare feature\n",
    "        for token in tokens:\n",
    "            if token in feature:\n",
    "                feature[token] += 1\n",
    "            else:\n",
    "                feature[token] =1\n",
    "                \n",
    "        # prepare turple\n",
    "        tmp = (feature, data[0])\n",
    "        \n",
    "        # add turple to list\n",
    "        fianl_list.append(tmp)        \n",
    "\n",
    "    return fianl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_test_data(list_data):\n",
    "    fianl_list = []\n",
    "    final_label = []\n",
    "    \n",
    "    for data in list_data:\n",
    "        feature = {}\n",
    "        tokens=kkma.morphs(data[1])\n",
    "        # prepare feature\n",
    "        for token in tokens:\n",
    "            if token in feature:\n",
    "                feature[token] += 1\n",
    "            else:\n",
    "                feature[token] =1\n",
    "                \n",
    "        tokens=kkma.morphs(data[3])\n",
    "        # prepare feature\n",
    "        for token in tokens:\n",
    "            if token in feature:\n",
    "                feature[token] += 1\n",
    "            else:\n",
    "                feature[token] =1\n",
    "                \n",
    "        # add data \n",
    "        fianl_list.append(feature)\n",
    "        \n",
    "        # add label\n",
    "        final_label.append(data[0])\n",
    "        \n",
    "    return fianl_list, final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(label, result):\n",
    "    result_dic = {}\n",
    "      \n",
    "    for x in range(len(label)):\n",
    "   \n",
    "        if label[x] == result[x]:\n",
    "            if label[x] + 'T' in result_dic:\n",
    "                result_dic[label[x]+'T'] += 1\n",
    "            else:\n",
    "                result_dic[label[x]+'T'] = 1\n",
    "        else:\n",
    "            if label[x] + 'F'+result[x] in result_dic:\n",
    "                result_dic[label[x]+'F'+result[x]] += 1\n",
    "            else:\n",
    "                result_dic[label[x]+'F'+result[x]] = 1\n",
    "            \n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple train / test\n",
      "594\n",
      "148\n",
      "pear train / test\n",
      "3095\n",
      "773\n",
      "potato train / test\n",
      "262\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# divide dataset into 2 set\n",
    "apple_train, apple_test = random_sample(apple, 0.2)\n",
    "pear_train, pear_test = random_sample(pear, 0.2)\n",
    "potato_train, potato_test = random_sample(potato, 0.2)\n",
    "\n",
    "print 'apple train / test'\n",
    "print len(apple_train)\n",
    "print len(apple_test)\n",
    "print 'pear train / test'\n",
    "print len(pear_train)\n",
    "print len(pear_test)\n",
    "print 'potato train / test'\n",
    "print len(potato_train)\n",
    "print len(potato_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apple_train_final = preprocess_train_data(apple_train)\n",
    "apple_test_final, apple_test_label = preprocess_test_data(apple_test)\n",
    "\n",
    "pear_train_final = preprocess_train_data(pear_train)\n",
    "pear_test_final, pear_test_label = preprocess_test_data(pear_test)\n",
    "\n",
    "potato_train_final = preprocess_train_data(potato_train)\n",
    "potato_test_final, potato_test_label = preprocess_test_data(potato_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxEnt classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify import maxent\n",
    "\n",
    "encoding1 = maxent.TypedMaxentFeatureEncoding.train(apple_train_final, count_cutoff=3, alwayson_features=True)\n",
    "me_classifier1 = maxent.MaxentClassifier.train(apple_train_final, bernoulli=False, encoding=encoding1, trace=0)\n",
    "me_result1 = me_classifier1.classify_many(apple_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoding2 = maxent.TypedMaxentFeatureEncoding.train(pear_train_final, count_cutoff=3, alwayson_features=True)\n",
    "me_classifier2 = maxent.MaxentClassifier.train(pear_train_final, bernoulli=False, encoding=encoding2, trace=0)\n",
    "me_result2 = me_classifier2.classify_many(pear_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoding3 = maxent.TypedMaxentFeatureEncoding.train(potato_train_final, count_cutoff=3, alwayson_features=True)\n",
    "me_classifier3 = maxent.MaxentClassifier.train(potato_train_final, bernoulli=False, encoding=encoding3, trace=0)\n",
    "me_result3 = me_classifier3.classify_many(potato_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "me_rdic1 = accuracy(apple_test_label, me_result1)\n",
    "me_rdic2 = accuracy(pear_test_label, me_result2)\n",
    "me_rdic3 = accuracy(potato_test_label, me_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\uc0ac\\uacfc__05/NNGF\\uc0ac\\uacfc__08/NNG': 8,\n",
       " u'\\uc0ac\\uacfc__05/NNGT': 65,\n",
       " u'\\uc0ac\\uacfc__08/NNGF\\uc0ac\\uacfc__05/NNG': 8,\n",
       " u'\\uc0ac\\uacfc__08/NNGT': 67}"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_rdic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\ubc30__01/NNGF\\ubc30__02/NNG': 28,\n",
       " u'\\ubc30__01/NNGF\\ubc30__03/NNG': 1,\n",
       " u'\\ubc30__01/NNGF\\ubc30__09/NNG': 9,\n",
       " u'\\ubc30__01/NNGT': 221,\n",
       " u'\\ubc30__02/NNGF\\ubc30__01/NNG': 26,\n",
       " u'\\ubc30__02/NNGF\\ubc30__03/NNG': 2,\n",
       " u'\\ubc30__02/NNGF\\ubc30__09/NNG': 11,\n",
       " u'\\ubc30__02/NNGT': 189,\n",
       " u'\\ubc30__03/NNGF\\ubc30__01/NNG': 9,\n",
       " u'\\ubc30__03/NNGF\\ubc30__02/NNG': 11,\n",
       " u'\\ubc30__03/NNGF\\ubc30__09/NNG': 1,\n",
       " u'\\ubc30__03/NNGT': 19,\n",
       " u'\\ubc30__09/NNGF\\ubc30__01/NNG': 9,\n",
       " u'\\ubc30__09/NNGF\\ubc30__02/NNG': 11,\n",
       " u'\\ubc30__09/NNGF\\ubc30__03/NNG': 1,\n",
       " u'\\ubc30__09/NNGT': 225}"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_rdic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\uac10\\uc790__01/NNGF\\uac10\\uc790__05/NNG': 1,\n",
       " u'\\uac10\\uc790__01/NNGT': 58,\n",
       " u'\\uac10\\uc790__05/NNGF\\uac10\\uc790__01/NNG': 3,\n",
       " u'\\uac10\\uc790__05/NNGT': 3}"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_rdic3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nb_classifier1 = nltk.classify.NaiveBayesClassifier.train(apple_train_final)\n",
    "nb_result1 = nb_classifier1.classify_many(apple_test_final)\n",
    "\n",
    "nb_classifier2 = nltk.classify.NaiveBayesClassifier.train(pear_train_final)\n",
    "nb_result2 = nb_classifier2.classify_many(pear_test_final)\n",
    "\n",
    "nb_classifier3 = nltk.classify.NaiveBayesClassifier.train(potato_train_final)\n",
    "nb_result3 = nb_classifier3.classify_many(potato_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_rdic1 = accuracy(apple_test_label, nb_result1)\n",
    "nb_rdic2 = accuracy(pear_test_label, nb_result2)\n",
    "nb_rdic3 = accuracy(potato_test_label, nb_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\uc0ac\\uacfc__05/NNGF\\uc0ac\\uacfc__08/NNG': 6,\n",
       " u'\\uc0ac\\uacfc__05/NNGT': 67,\n",
       " u'\\uc0ac\\uacfc__08/NNGF\\uc0ac\\uacfc__05/NNG': 4,\n",
       " u'\\uc0ac\\uacfc__08/NNGT': 71}"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rdic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\ubc30__01/NNGF\\ubc30__02/NNG': 11,\n",
       " u'\\ubc30__01/NNGF\\ubc30__03/NNG': 68,\n",
       " u'\\ubc30__01/NNGF\\ubc30__09/NNG': 8,\n",
       " u'\\ubc30__01/NNGT': 172,\n",
       " u'\\ubc30__02/NNGF\\ubc30__01/NNG': 13,\n",
       " u'\\ubc30__02/NNGF\\ubc30__03/NNG': 59,\n",
       " u'\\ubc30__02/NNGF\\ubc30__09/NNG': 13,\n",
       " u'\\ubc30__02/NNGT': 143,\n",
       " u'\\ubc30__03/NNGF\\ubc30__02/NNG': 2,\n",
       " u'\\ubc30__03/NNGF\\ubc30__09/NNG': 2,\n",
       " u'\\ubc30__03/NNGT': 36,\n",
       " u'\\ubc30__09/NNGF\\ubc30__01/NNG': 3,\n",
       " u'\\ubc30__09/NNGF\\ubc30__02/NNG': 5,\n",
       " u'\\ubc30__09/NNGF\\ubc30__03/NNG': 35,\n",
       " u'\\ubc30__09/NNGT': 203}"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rdic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\uac10\\uc790__01/NNGF\\uac10\\uc790__05/NNG': 25,\n",
       " u'\\uac10\\uc790__01/NNGT': 34,\n",
       " u'\\uac10\\uc790__05/NNGT': 6}"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rdic3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
