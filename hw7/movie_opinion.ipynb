{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 2016. 4. 17\n",
    "\n",
    "@author: dato\n",
    "@desc: cnlp hw7 (movie rating classification)\n",
    "'''\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import io\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = './movie.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of doc : 121\n"
     ]
    }
   ],
   "source": [
    "f = io.open(data_file, 'r', encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "total_doc = len(lines)\n",
    "print 'total # of doc : ' + str(total_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0: 제목\n",
    "1: rating (1~4, 5~7, 8~10)\n",
    "2: comment\n",
    "\n",
    "word_2_index = {} : 입력 word 를 index 로 바꾼 값\n",
    "index_2_word = [] : index 가 의미하는 word\n",
    "\n",
    "cnt_dic_all = {} : 전체 morph dictionary \n",
    "cnt_dic_pos = {} : positive class dictionary \n",
    "cnt_dic_neut = {} : neutral class dictionry\n",
    "cnt_dic_neg = {} : negative class dictionary\n",
    "\n",
    "cnt_class_pos : postive class count\n",
    "cnt_class_neut : neutral class count\n",
    "cnt_class_neg : negative class count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bulid_dictionary (tokens, word_to_index, index_to_word):\n",
    "    \n",
    "    for token in tokens:\n",
    "\n",
    "        if token not in word_to_index:\n",
    "            word_to_index[token] = len(word_to_index)\n",
    "            index_to_word.append(token)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_lines = [line.split('\\t') for line in lines]\n",
    "\n",
    "# change rating into class\n",
    "for line in parsed_lines:\n",
    "    rating = float(line[1])\n",
    "    \n",
    "    if rating >= 8.0:\n",
    "        line[1] = 'POS'\n",
    "    elif rating >= 5.0:\n",
    "        line[1] = 'NEUT'\n",
    "    else:\n",
    "        line[1] = 'NEG' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1138\n"
     ]
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "\n",
    "word_to_index = {}\n",
    "index_to_word = []\n",
    "\n",
    "\n",
    "for line in parsed_lines:\n",
    "    # 0: title\n",
    "    # 1: rating\n",
    "    # 2: comment\n",
    "    tokens=kkma.morphs(line[2])\n",
    "    bulid_dictionary(tokens, word_to_index, index_to_word)\n",
    "\n",
    "print len(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count word within class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize word count dictionary of each class with bias ( =1 )\n",
    "\n",
    "cnt_dic_pos = {}\n",
    "cnt_dic_neut = {}\n",
    "nt_dic_neg = {}\n",
    "\n",
    "# Laplace smoothing (add one)\n",
    "cnt_dic_pos = dict( (nkey, 1) for nkey in [key for key in word_to_index.keys()])\n",
    "cnt_dic_neut = dict( (nkey, 1) for nkey in [key for key in word_to_index.keys()])\n",
    "cnt_dic_neg = dict( (nkey, 1) for nkey in [key for key in word_to_index.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_word_to_class_info(tokens, cnt_dic_class):\n",
    "    \n",
    "    for token in tokens:\n",
    "        cnt_dic_class[token] = cnt_dic_class[token] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt_class_pos = 0\n",
    "cnt_class_neut = 0\n",
    "cnt_class_neg = 0\n",
    "\n",
    "for line in parsed_lines:\n",
    "    # 0: title\n",
    "    # 1: rating\n",
    "    # 2: comment\n",
    "    tokens=kkma.morphs(line[2])\n",
    "\n",
    "    if  line[1] == 'POS':\n",
    "        add_word_to_class_info(tokens, cnt_dic_pos)\n",
    "        cnt_class_pos = cnt_class_pos + 1\n",
    "        \n",
    "    elif line[1] == 'NEUT':\n",
    "        add_word_to_class_info(tokens, cnt_dic_neut)\n",
    "        cnt_class_neut  = cnt_class_neut + 1\n",
    "    else:\n",
    "        add_word_to_class_info(tokens, cnt_dic_neg)\n",
    "        cnt_class_neg  = cnt_class_neg + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_class_number : 60\n",
      "neut_class_number : 33\n",
      "neg_class_number : 28\n",
      "pos_class_word_cnt_sum : 3149\n",
      "neut_class_word_cnt_sum : 2716\n",
      "neg_class_word_cnt_sum : 2138\n"
     ]
    }
   ],
   "source": [
    "print 'pos_class_number : ' + str(cnt_class_pos)\n",
    "print 'neut_class_number : ' + str(cnt_class_neut)\n",
    "print 'neg_class_number : ' + str(cnt_class_neg)\n",
    "\n",
    "print 'pos_class_word_cnt_sum : ' + str(sum(cnt_dic_pos.values())) \n",
    "print 'neut_class_word_cnt_sum : ' + str(sum(cnt_dic_neut.values()))\n",
    "print 'neg_class_word_cnt_sum : ' + str(sum(cnt_dic_neg.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Prior, Likelihood table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log Prior calculation\n",
    "\n",
    "import math\n",
    "\n",
    "log_prior_pos =  math.log( (float)(cnt_class_pos) / (float)(total_doc) )\n",
    "log_prior_neut =  math.log( (float)(cnt_class_neut) / (float)(total_doc) )\n",
    "log_prior_neg =  math.log( (float)(cnt_class_neg) / (float)(total_doc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Likelihood table calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_likelihood_table(cnt_dic_class):\n",
    "    \n",
    "    new_talbe = {}\n",
    "    word_sum = sum(cnt_dic_class.values())    \n",
    "    new_table = dict( (key, math.log((float)(value)/(float)(word_sum)) ) for (key, value) in cnt_dic_class.iteritems())    \n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149\n",
      "2716\n",
      "2138\n",
      "-8475.56006226\n",
      "-8424.51202739\n",
      "-8286.45807037\n"
     ]
    }
   ],
   "source": [
    "LL_dic_pos = {}\n",
    "LL_dic_neut = {}\n",
    "LL_dic_neg = {}\n",
    "\n",
    "LL_dic_pos = cal_likelihood_table(cnt_dic_pos)\n",
    "LL_dic_neut = cal_likelihood_table(cnt_dic_neut)\n",
    "LL_dic_neg = cal_likelihood_table(cnt_dic_neg)\n",
    "\n",
    "print sum(cnt_dic_pos.values())\n",
    "print sum(cnt_dic_neut.values())\n",
    "print sum(cnt_dic_neg.values())\n",
    "\n",
    "print sum(LL_dic_pos.values())\n",
    "print sum(LL_dic_neut.values())\n",
    "print sum(LL_dic_neg.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluation with naive bayes classification\n",
    "\n",
    "eval[][0] = Pos LL\n",
    "\n",
    "eval[][1] = Neut LL\n",
    "\n",
    "eval[][2] = Neg LL\n",
    "\n",
    "eval[][3] = predicted class\n",
    "\n",
    "eval[][4] = Pos posterior prob.\n",
    "\n",
    "eval[][5] = Neut posterior prob.\n",
    "\n",
    "eval[][6] = Neg posterior prob.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_tokens(tokens, eval):\n",
    "    \n",
    "    for token in tokens:\n",
    "        \n",
    "        # dictionay 에 없는 token 은 무시\n",
    "        if token not in word_to_index:\n",
    "            continue\n",
    "        \n",
    "        eval[0] += LL_dic_pos[token]\n",
    "        eval[1] += LL_dic_neut[token]\n",
    "        eval[2] += LL_dic_neg[token]\n",
    "        \n",
    "    eval[0] += log_prior_pos\n",
    "    eval[1] += log_prior_neut\n",
    "    eval[2] += log_prior_neg\n",
    "    \n",
    "       \n",
    "    if (eval[0] >= eval[1]) & (eval[0] >= eval[2]):\n",
    "        eval[3] = 'POS'\n",
    "        max = eval[0]\n",
    "        \n",
    "    elif eval[1] >= eval[2]:\n",
    "        eval[3] = 'NEUT'\n",
    "        max = eval[1]\n",
    "        \n",
    "    else:\n",
    "        eval[3] = 'NEG'\n",
    "        max = eval[2]\n",
    "        \n",
    "        \n",
    "    nom = math.exp(eval[0] - max) + math.exp(eval[1] - max) + math.exp(eval[2] - max)\n",
    "    \n",
    "    eval[4] = math.exp(eval[0] - max) / nom\n",
    "    eval[5] = math.exp(eval[1] - max) / nom\n",
    "    eval[6] = math.exp(eval[2] - max) / nom\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval = [ [0 for x in range(7)] for x in range(len(parsed_lines)) ]\n",
    "\n",
    "cnt = 0\n",
    "for line in parsed_lines:\n",
    "    \n",
    "    tokens = tokens=kkma.morphs(line[2])\n",
    "    eval_tokens(tokens, eval[cnt])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate In-sample Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 117\n",
      "incorrect: 4\n",
      "accuracy: 0.96694214876\n",
      "error: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 10, 104, 114]"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "error = []\n",
    "\n",
    "for x in range( len(parsed_lines) ):\n",
    "    \n",
    "    if parsed_lines[x][1] == eval[x][3]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        error.append(x)\n",
    "        \n",
    "print 'correct: ' + str(correct)\n",
    "print 'incorrect: ' + str(incorrect)\n",
    "print 'accuracy: ' + str( (float)(correct) / (float)(correct+incorrect) )\n",
    "print 'error: '\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR CHECK\n",
      "data: 원더우먼 사랑해요~\n",
      "label: NEUT\n",
      "predict: \n",
      "['POS', 0.8279246030050293, 0.16789855771054446, 0.0041768392844263895]\n",
      "\n",
      "\n",
      "data: 초반 좀 지루해서 졸렸어요. 그래도 마지막 원더우먼 짱!오랫만에 추억의 원더우먼 멋졌어요.\n",
      "label: NEUT\n",
      "predict: \n",
      "['POS', 0.7758874793281848, 0.2241122884898388, 2.3218197650805632e-07]\n",
      "\n",
      "\n",
      "data: 잭스나이더는 영화바닥에서 영원히 떠나야함.\n",
      "label: NEG\n",
      "predict: \n",
      "['NEUT', 0.035947812198292156, 0.5217493424948533, 0.4423028453068546]\n",
      "\n",
      "\n",
      "data: 슈퍼맨\n",
      "label: POS\n",
      "predict: \n",
      "['NEUT', 0.34514036217055305, 0.3912720342080112, 0.2635876036214357]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'ERROR CHECK'\n",
    "\n",
    "for index in error:\n",
    "    print 'data: ' + parsed_lines[index][2]\n",
    "    print 'label: ' + parsed_lines[index][1]\n",
    "    print 'predict: '\n",
    "    print eval[index][3:]\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "원\t-5.01031778338\t-5.50902021588\t-6.05818817915\n",
      "드\t-5.01031778338\t-5.34196613122\t-6.28133173047\n",
      "어\t-4.68754439111\t-4.68803966381\t-4.83441274753\n",
      "우먼\t-5.05910794755\t-5.50902021588\t-6.28133173047\n",
      "사랑\t-8.0548402211\t-7.21376830812\t-7.66762609158\n",
      "하\t-3.94396635693\t-3.88156379794\t-4.33542158141\n",
      "어요\t-6.66854585998\t-6.52062112756\t-7.66762609158\n",
      "~\t-6.44540230867\t-7.21376830812\t-6.28133173047\n",
      "\n",
      "\n",
      "초반\t-6.66854585998\t-6.52062112756\t-6.97447891103\n",
      "좀\t-5.97539867942\t-7.21376830812\t-6.97447891103\n",
      "지루\t-6.95622793243\t-5.827473947\t-6.97447891103\n",
      "하\t-3.94396635693\t-3.88156379794\t-4.33542158141\n",
      "어서\t-5.97539867942\t-6.11515601945\t-6.28133173047\n",
      "졸리\t-8.0548402211\t-7.21376830812\t-6.97447891103\n",
      "었\t-5.05910794755\t-4.72886165833\t-5.10267673412\n",
      "어요\t-6.66854585998\t-6.52062112756\t-7.66762609158\n",
      ".\t-4.47132128264\t-3.9556717701\t-4.40952955356\n",
      "그리하\t-6.66854585998\t-7.21376830812\t-6.56901380292\n",
      "여도\t-6.66854585998\t-7.21376830812\t-6.56901380292\n",
      "마지막\t-7.36169304054\t-6.11515601945\t-7.66762609158\n",
      "원\t-5.01031778338\t-5.50902021588\t-6.05818817915\n",
      "드\t-5.01031778338\t-5.34196613122\t-6.28133173047\n",
      "어\t-4.68754439111\t-4.68803966381\t-4.83441274753\n",
      "우먼\t-5.05910794755\t-5.50902021588\t-6.28133173047\n",
      "짱\t-5.97539867942\t-7.21376830812\t-7.66762609158\n",
      "!\t-5.48989086364\t-7.21376830812\t-7.66762609158\n",
      "오랫만\t-8.0548402211\t-7.21376830812\t-7.66762609158\n",
      "에\t-4.96379776774\t-4.77142127275\t-5.36504099859\n",
      "추억\t-7.36169304054\t-6.80830320001\t-6.97447891103\n",
      "의\t-4.41725406137\t-4.91118321512\t-5.1827194418\n",
      "원\t-5.01031778338\t-5.50902021588\t-6.05818817915\n",
      "드\t-5.01031778338\t-5.34196613122\t-6.28133173047\n",
      "어\t-4.68754439111\t-4.68803966381\t-4.83441274753\n",
      "우먼\t-5.05910794755\t-5.50902021588\t-6.28133173047\n",
      "멋지\t-8.0548402211\t-7.21376830812\t-7.66762609158\n",
      "었\t-5.05910794755\t-4.72886165833\t-5.10267673412\n",
      "어요\t-6.66854585998\t-6.52062112756\t-7.66762609158\n",
      ".\t-4.47132128264\t-3.9556717701\t-4.40952955356\n",
      "\n",
      "\n",
      "잭\t-6.95622793243\t-6.52062112756\t-6.28133173047\n",
      "슬\t-6.95622793243\t-6.52062112756\t-6.56901380292\n",
      "나\t-5.34679002\t-5.60433039568\t-5.58818454991\n",
      "이\t-3.66039106643\t-3.74803240532\t-4.17111853012\n",
      "덜\t-8.0548402211\t-6.52062112756\t-6.97447891103\n",
      "는\t-4.29364010541\t-4.24335384255\t-4.67189381803\n",
      "영화\t-4.79674368308\t-4.77142127275\t-5.1827194418\n",
      "바닥\t-8.0548402211\t-7.90691548868\t-6.97447891103\n",
      "에서\t-6.44540230867\t-6.80830320001\t-6.56901380292\n",
      "영원히\t-8.0548402211\t-7.90691548868\t-6.97447891103\n",
      "떠나\t-8.0548402211\t-7.21376830812\t-6.97447891103\n",
      "아야\t-7.36169304054\t-7.21376830812\t-6.97447891103\n",
      "하\t-3.94396635693\t-3.88156379794\t-4.33542158141\n",
      "ㅁ\t-5.34679002\t-5.70969091134\t-5.87586662236\n",
      ".\t-4.47132128264\t-3.9556717701\t-4.40952955356\n",
      "\n",
      "\n",
      "슈퍼맨\t-5.85761564376\t-5.13432676644\t-5.36504099859\n"
     ]
    }
   ],
   "source": [
    "for index in error:\n",
    "    tmp = parsed_lines[index][2]\n",
    "    tmpToken = kkma.morphs(tmp)\n",
    "    print '\\n'\n",
    "    \n",
    "    for token in tmpToken:\n",
    "        print token + '\\t'+ str(LL_dic_pos[token]) + '\\t'+ str(LL_dic_neut[token]) +'\\t'+ str(LL_dic_neg[token])      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print posterior prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class prettyfloat(float):\n",
    "    def __repr__(self):\n",
    "        return \"%0.10f\" % self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEUT', 0.0000000173, 0.9999999827, 0.0000000000]\n",
      "['NEG', 0.0000201068, 0.0044618363, 0.9955180569]\n",
      "['POS', 0.9843024546, 0.0143627180, 0.0013348274]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['POS', 0.9904780703, 0.0032440299, 0.0062778999]\n",
      "['NEUT', 0.0000000242, 0.9999999758, 0.0000000000]\n",
      "['NEG', 0.1376781257, 0.0215640106, 0.8407578638]\n",
      "['NEG', 0.0198190733, 0.0059545131, 0.9742264136]\n",
      "['NEUT', 0.0000065002, 0.9999369989, 0.0000565008]\n",
      "['POS', 0.8279246030, 0.1678985577, 0.0041768393]\n",
      "['POS', 0.7758874793, 0.2241122885, 0.0000002322]\n",
      "['NEUT', 0.0000000508, 0.9999996286, 0.0000003206]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['POS', 0.9994672166, 0.0005327552, 0.0000000283]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['POS', 0.9999999998, 0.0000000002, 0.0000000000]\n",
      "['NEUT', 0.0000060573, 0.9999937863, 0.0000001563]\n",
      "['NEG', 0.0000000000, 0.0000000000, 1.0000000000]\n",
      "['NEUT', 0.0000000048, 0.9999999949, 0.0000000002]\n",
      "['NEUT', 0.0000001006, 0.9999998981, 0.0000000013]\n",
      "['NEUT', 0.0740591468, 0.9235880980, 0.0023527552]\n",
      "['POS', 0.8126718939, 0.0916627795, 0.0956653266]\n",
      "['NEUT', 0.0000020079, 0.9999979885, 0.0000000036]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['NEUT', 0.0000667453, 0.9999332488, 0.0000000059]\n",
      "['NEG', 0.0000000001, 0.0000000283, 0.9999999716]\n",
      "['NEG', 0.0153171770, 0.0031051422, 0.9815776808]\n",
      "['NEUT', 0.0000000180, 0.9999999820, 0.0000000000]\n",
      "['POS', 0.9999981234, 0.0000018729, 0.0000000037]\n",
      "['NEG', 0.0000000001, 0.0000000000, 0.9999999999]\n",
      "['NEUT', 0.0000000239, 0.9999959648, 0.0000040113]\n",
      "['NEUT', 0.0000376526, 0.9999623442, 0.0000000032]\n",
      "['NEG', 0.0003572564, 0.0045129900, 0.9951297537]\n",
      "['NEG', 0.0000000000, 0.0000000066, 0.9999999934]\n",
      "['POS', 0.9999988773, 0.0000011223, 0.0000000004]\n",
      "['POS', 0.9999993850, 0.0000006047, 0.0000000103]\n",
      "['NEUT', 0.0003211681, 0.9996788283, 0.0000000036]\n",
      "['POS', 0.9999984692, 0.0000015306, 0.0000000002]\n",
      "['NEG', 0.0000362987, 0.0000360913, 0.9999276100]\n",
      "['POS', 0.8971687791, 0.0371532817, 0.0656779392]\n",
      "['NEG', 0.0042717516, 0.0204961751, 0.9752320732]\n",
      "['POS', 0.9999999961, 0.0000000039, 0.0000000000]\n",
      "['POS', 0.9999999486, 0.0000000514, 0.0000000000]\n",
      "['NEUT', 0.0000173096, 0.9999824414, 0.0000002490]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['NEUT', 0.1175464049, 0.6180097048, 0.2644438903]\n",
      "['NEUT', 0.1138670738, 0.8528814753, 0.0332514509]\n",
      "['NEUT', 0.0003541651, 0.9996458344, 0.0000000005]\n",
      "['NEG', 0.0035231613, 0.0463199102, 0.9501569284]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['POS', 0.9809411673, 0.0190540157, 0.0000048171]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['POS', 0.9997451060, 0.0002239750, 0.0000309190]\n",
      "['POS', 0.9827125140, 0.0170687065, 0.0002187795]\n",
      "['POS', 0.9982934285, 0.0016817331, 0.0000248384]\n",
      "['POS', 0.9999959285, 0.0000040546, 0.0000000169]\n",
      "['POS', 0.9999999699, 0.0000000005, 0.0000000297]\n",
      "['NEG', 0.0000000000, 0.0000000000, 1.0000000000]\n",
      "['NEG', 0.1531827399, 0.2265104842, 0.6203067758]\n",
      "['POS', 0.6178813478, 0.3817531670, 0.0003654852]\n",
      "['NEG', 0.0000000000, 0.0000000000, 1.0000000000]\n",
      "['POS', 0.9867960170, 0.0123493364, 0.0008546466]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['NEUT', 0.0036136874, 0.9949363703, 0.0014499423]\n",
      "['NEUT', 0.0000000000, 1.0000000000, 0.0000000000]\n",
      "['POS', 0.9998541054, 0.0001458102, 0.0000000844]\n",
      "['POS', 0.9999999625, 0.0000000375, 0.0000000000]\n",
      "['NEUT', 0.0000000367, 0.9999999633, 0.0000000000]\n",
      "['POS', 0.9999959812, 0.0000040185, 0.0000000003]\n",
      "['NEG', 0.0056530788, 0.0194264336, 0.9749204876]\n",
      "['POS', 0.9925871641, 0.0020285247, 0.0053843111]\n",
      "['NEG', 0.0010942264, 0.0000439809, 0.9988617928]\n",
      "['POS', 0.9868602993, 0.0087335112, 0.0044061895]\n",
      "['POS', 0.9881262509, 0.0013094374, 0.0105643117]\n",
      "['POS', 0.9999985897, 0.0000014070, 0.0000000033]\n",
      "['POS', 0.9998187144, 0.0001370008, 0.0000442848]\n",
      "['POS', 0.9998501306, 0.0000822341, 0.0000676353]\n",
      "['POS', 0.9940658103, 0.0047949467, 0.0011392430]\n",
      "['POS', 0.9929537783, 0.0023520277, 0.0046941940]\n",
      "['POS', 0.9999905549, 0.0000074235, 0.0000020216]\n",
      "['POS', 0.9999481546, 0.0000516256, 0.0000002199]\n",
      "['POS', 0.9914592258, 0.0076512682, 0.0008895059]\n",
      "['POS', 0.9999163809, 0.0000816308, 0.0000019884]\n",
      "['POS', 0.9999986078, 0.0000011013, 0.0000002909]\n",
      "['POS', 0.9999993585, 0.0000006415, 0.0000000000]\n",
      "['POS', 0.9974476830, 0.0005945694, 0.0019577476]\n",
      "['NEUT', 0.0070521612, 0.9548354630, 0.0381123758]\n",
      "['POS', 0.9999840726, 0.0000159261, 0.0000000013]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['POS', 0.9999998567, 0.0000001433, 0.0000000001]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['POS', 0.9995708340, 0.0004223497, 0.0000068163]\n",
      "['NEG', 0.0000003274, 0.0000036724, 0.9999960002]\n",
      "['POS', 0.9998986827, 0.0000922408, 0.0000090765]\n",
      "['NEG', 0.1144213516, 0.0002936346, 0.8852850138]\n",
      "['POS', 0.8580343650, 0.0715917281, 0.0703739069]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['POS', 0.9919009646, 0.0013317324, 0.0067673030]\n",
      "['POS', 0.9722547606, 0.0222303099, 0.0055149295]\n",
      "['NEG', 0.2998824425, 0.1352972013, 0.5648203563]\n",
      "['NEG', 0.0111668806, 0.0134709337, 0.9753621857]\n",
      "['NEG', 0.0003574335, 0.0002573074, 0.9993852591]\n",
      "['NEG', 0.2069366694, 0.0501367405, 0.7429265901]\n",
      "['POS', 0.9999999625, 0.0000000007, 0.0000000368]\n",
      "['NEUT', 0.0359478122, 0.5217493425, 0.4423028453]\n",
      "['NEG', 0.1555518957, 0.1742619424, 0.6701861619]\n",
      "['POS', 1.0000000000, 0.0000000000, 0.0000000000]\n",
      "['NEUT', 0.0171349486, 0.9828650513, 0.0000000001]\n",
      "['NEUT', 0.0000000921, 0.9999995447, 0.0000003632]\n",
      "['NEG', 0.0027640497, 0.0024328126, 0.9948031378]\n",
      "['POS', 0.9994205449, 0.0005762441, 0.0000032110]\n",
      "['NEUT', 0.0052403804, 0.9755662379, 0.0191933817]\n",
      "['POS', 0.9357309137, 0.0346309045, 0.0296381817]\n",
      "['POS', 0.9999999949, 0.0000000051, 0.0000000000]\n",
      "['NEUT', 0.3451403622, 0.3912720342, 0.2635876036]\n",
      "['POS', 0.9977989273, 0.0006128542, 0.0015882185]\n",
      "['NEG', 0.0000091025, 0.0000003158, 0.9999905818]\n",
      "['POS', 0.9999999841, 0.0000000159, 0.0000000000]\n",
      "['NEG', 0.0000000110, 0.0000000000, 0.9999999890]\n",
      "['POS', 0.9972918325, 0.0007443986, 0.0019637689]\n",
      "['NEUT', 0.0025243515, 0.9944146771, 0.0030609713]\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(parsed_lines)):\n",
    "    eval[index][4:] = map(prettyfloat, eval[index][4:])    \n",
    "    print eval[index][3:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sample test] Single Sentence Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_single_sentence( tmpSen ):\n",
    "\n",
    "    tmpSen = unicode(sample.decode('utf-8'))\n",
    "    \n",
    "    rst = [0 for x in range(7)]\n",
    "    tmpToken = kkma.morphs(tmpSen)\n",
    "    eval_tokens(tmpToken, rst)\n",
    "\n",
    "    print 'INPUT: ' + tmpSen\n",
    "    print '\\n'\n",
    "    print 'OUTPUT: \\n'\n",
    "    \n",
    "    print 'log prior probabilities P(c):'\n",
    "    print 'postive \\t neutral \\t negative'\n",
    "    print str(log_prior_pos) + '\\t' + str(log_prior_neut) + '\\t' + str(log_prior_neg)\n",
    "    print '\\n'\n",
    "\n",
    "    print 'log likelihood P(v|c):'\n",
    "    print 'word_id \\t postive \\t neutral \\t negative'\n",
    "    for token in tmpToken:\n",
    "        if token not in word_to_index:\n",
    "            print token +  '\\t' + str(0) + '\\t' +  str(0) +  '\\t' + str(0)\n",
    "        else:\n",
    "            print token +  '\\t' + str(LL_dic_pos[token]) + '\\t' +  str(LL_dic_neut[token]) +  '\\t' + str(LL_dic_neg[token])\n",
    "\n",
    "    print '\\n'\n",
    "    print 'log P(c) + sum log P(v|c) :'\n",
    "    print 'postive \\t neutral \\t negative'\n",
    "    print str(rst[0]) + '\\t' + str(rst[1]) + '\\t' + str(rst[2])\n",
    "\n",
    "    print '\\n'\n",
    "    print 'posterior probabilities:'\n",
    "    print 'positive \\t neutral \\t negative'\n",
    "    print str(rst[4]) + '\\t' + str(rst[5]) + '\\t' + str(rst[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = '정말 재밌게 본 영화 강추!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = '내 인생 최악 졸작 영화. 알바 댓글에 속았음'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: 슈퍼맨\n",
      "\n",
      "\n",
      "OUTPUT: \n",
      "\n",
      "log prior probabilities P(c):\n",
      "postive \t neutral \t negative\n",
      "-0.701445983375\t-1.29928298413\t-1.46358603542\n",
      "\n",
      "\n",
      "log likelihood P(v|c):\n",
      "word_id \t postive \t neutral \t negative\n",
      "슈퍼맨\t-5.85761564376\t-5.13432676644\t-5.36504099859\n",
      "\n",
      "\n",
      "log P(c) + sum log P(v|c) :\n",
      "postive \t neutral \t negative\n",
      "-6.55906162714\t-6.43360975057\t-6.82862703401\n",
      "\n",
      "\n",
      "posterior probabilities:\n",
      "positive \t neutral \t negative\n",
      "0.345140362171\t0.391272034208\t0.263587603621\n"
     ]
    }
   ],
   "source": [
    "eval_single_sentence(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
